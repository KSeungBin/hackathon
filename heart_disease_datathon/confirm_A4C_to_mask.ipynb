{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_a2c import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_PATH='./test_image/A4C/'\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = 'cpu'\n",
    "W_SIZE = 600\n",
    "H_SIZE = 400\n",
    "BATCH_SIZE = 1\n",
    "output_path = './outputs/A4C/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_val = os.listdir(VALIDATION_PATH)\n",
    "npy_list_val = list()\n",
    "png_list_val = list()\n",
    "\n",
    "for name in file_list_val:\n",
    "    if name[-4:]=='.png':\n",
    "        png_list_val.append(name)\n",
    "    elif name[-4:]=='.npy':\n",
    "        npy_list_val.append(name)\n",
    "\n",
    "dataset_val = list()\n",
    "for name in png_list_val:\n",
    "    common_name = name[:-4]\n",
    "    # npy_obj = np.load(VALIDATION_PATH+common_name+'.npy')\n",
    "    # print(npy_obj)\n",
    "    # break\n",
    "    # npy_obj = cv2.resize(npy_obj, (W_SIZE,H_SIZE)).reshape(1,H_SIZE,W_SIZE)*255\n",
    "    # npy_obj = cv2.resize(npy_obj, (W_SIZE,H_SIZE)).reshape(1,H_SIZE,W_SIZE)*255\n",
    "    png_obj = cv2.imread(VALIDATION_PATH+common_name+'.png', 0)\n",
    "    h, w = png_obj.shape\n",
    "    png_obj = cv2.resize(png_obj, (W_SIZE,H_SIZE)).reshape(1,H_SIZE,W_SIZE)\n",
    "    # dataset_val.append((png_obj, npy_obj))\n",
    "    dataset_val.append((png_obj,(h,w, name)))\n",
    "\n",
    "test_dataset = dataset_val\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "BEST_MODEL_PATH = 'best_model_A4C.pth'\n",
    "unet = DoubleUNet(1,1).to(DEVICE)\n",
    "unet.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_collect = list()\n",
    "LABEL_TRUE_SUM_collect = list()\n",
    "PREDICTI_TRUE_SUM_collect = list()\n",
    "outputs = list()\n",
    "for img, (h, w, name) in tqdm(test_loader):\n",
    "    img = img.to(DEVICE)\n",
    "    # label_test = label.float().to(DEVICE)\n",
    "                \n",
    "    outputs_test,  adap_outputs, adap_label = unet(img.float(), img.float())\n",
    "    tmp = outputs_test.detach().numpy().squeeze().squeeze()\n",
    "    ret = cv2.resize(tmp, (int(w),int(h)))\n",
    "    ret = np.round(ret).astype(int)\n",
    "    cv2.imwrite(output_path+str(name[0]), ret*255)\n",
    "    outputs.append(ret)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "900057b023b5ce44058c8c58dc34b5b442c7c12c681212cd6c3341775c6bcb10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
